# Конфигурационный файл для LLaMA API
# Этот файл содержит настройки для управления поведением языковой модели при генерации текста.
# Измените значения параметров в соответствии с вашими потребностями.
# Не изменяйте названия параметров и не удаляйте их.

# Шаблон промпта. {} будет заменено на текст пользователя
prompt_template = "Исправь следующий текст: {}"

# Системный промпт, который задает контекст для модели
system_prompt = """
Ваша задача - проверить и исправить текст, полученный в результате распознавания речи. Следуйте этим инструкциям:
1. Внимательно прочитайте предоставленный текст.
2. Исправьте очевидные орфографические и грамматические ошибки.
3. Если встречаются искаженные или неправильно распознанные слова, замените их на наиболее подходящие по контексту и смыслу варианты.
4. Сохраняйте исходную структуру предложений и общий смысл текста.
5. Не удаляй и не добавляй новую информацию и не меняй смысл сказанного!
6. Если какое-то слово или фраза непонятны и вы не уверены в правильной замене, оставьте их без изменений, пометив [неясно] в квадратных скобках.
7. После внесения исправлений предоставьте откорректированную версию текста.
8. Предоставь только исправленный текст!.
Цель - получить грамматически правильный и понятный текст, максимально близкий к оригинальному высказыванию говорящего.
"""

# Температура выборки. Более высокие значения делают вывод более случайным, более низкие - более детерминированным
# Диапазон: 0.0 - 1.0
temperature = 0.8

# Фактор для вычисления n_predict. Итоговое значение n_predict будет равно длине входного текста, умноженной на этот фактор
n_predict_factor = 1.2

# Top-k выборка. Ограничивает выбор следующего токена k наиболее вероятными вариантами
# Диапазон: 1 - ∞, где ∞ означает отключение top-k
top_k = 40

# Top-p (ядерная) выборка. Модель рассматривает наиболее вероятные токены с суммарной вероятностью p
# Диапазон: 0.0 - 1.0, где 1.0 означает отключение top-p
top_p = 0.95

# Минимальный порог вероятности. Токены с вероятностью ниже min_p не рассматриваются
# Диапазон: 0.0 - 1.0
min_p = 0.05

# Штраф за повторение. Значения > 1.0 уменьшают вероятность повторения токенов
# Диапазон: 1.0 - 2.0
repeat_penalty = 1.1

# Штраф за присутствие. Применяется к токенам, которые уже присутствуют в сгенерированном тексте
# Диапазон: -2.0 - 2.0
presence_penalty = 0.0

# Штраф за частоту. Применяется к токенам пропорционально их частоте в сгенерированном тексте
# Диапазон: -2.0 - 2.0
frequency_penalty = 0.0

# Режим Mirostat (адаптивный контроль перплексии при инференсе)
# Mirostat динамически регулирует параметры выборки во время генерации текста для поддержания заданного уровня перплексии
# 0 = отключен, 1 = Mirostat, 2 = Mirostat 2.0 (улучшенная версия)
mirostat = 0

# Целевая перплексия для Mirostat (tau)
# Контролирует уровень "неожиданности" в генерируемом тексте. Более низкие значения делают текст более предсказуемым,
# более высокие — более разнообразным и потенциально более творческим.
# Рекомендуемый диапазон: 2.0 - 5.0
mirostat_tau = 5.0

# Скорость обновления для Mirostat (eta)
# Контролирует, как быстро Mirostat корректирует параметры выборки во время генерации.
# Более высокие значения позволяют быстрее адаптироваться, но могут привести к нестабильности.
# Рекомендуемый диапазон: 0.001 - 0.1
mirostat_eta = 0.1

# Список строк, при появлении которых генерация будет остановлена
stop = ["</s>", "User:"]